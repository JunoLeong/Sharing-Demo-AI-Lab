{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ee09b8e",
   "metadata": {},
   "source": [
    "# Demo: Local LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaead475",
   "metadata": {},
   "source": [
    "## Ollama and Langchain\n",
    "\n",
    "### What is Ollama?\n",
    "- A local LLM runtime to run models (Llama, Mistral, Qwen, Phi, etc.) on local machine with simple commands.\n",
    "- Pull & run models:\n",
    "  ```bash\n",
    "    ollama serve\n",
    "    ollama pull llama3.2\n",
    "    ollama run llama3.2\n",
    "    ``` \n",
    "- Exposes an HTTP API (default http://localhost:11434) for chat, embeddings, and model management.\n",
    "- Great for privacy, offline work, reproducible demos, and avoiding cloud costs.\n",
    "- **Website:** [ollama.com](https://ollama.com)\n",
    "\n",
    "---\n",
    "### What is Langchain?\n",
    "- A Python framework to build LLM apps by composing blocks:\n",
    "- Models (ChatModel, LLM), Embeddings, Document Loaders, TextSplitters, VectorStores, and Chains/Runnables.\n",
    "- Providing unified interface for different providers (local or cloud), plus utilities for RAG, tools, and orchestration.\n",
    "- Building blocks to turn that into apps\n",
    "- **Docs:** [LangChain Python Docs](https://docs.langchain.com/oss/python/langchain/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737865c8",
   "metadata": {},
   "source": [
    "## Set Up Environemnt\n",
    "\n",
    "Download the necessary packages for building RAG pipelines\n",
    "\n",
    "- langchain\n",
    "Core framework for building LLM apps (chains, prompts, runnables). You use it for text splitters, message types, and composing the RAG flow.\n",
    "\n",
    "- langchain_community\n",
    "Community-maintained integrations that were split out of langchain. Includes loaders (e.g., PyPDFLoader) and many third-party connectors you call in your code.\n",
    "\n",
    "- langchain-ollama\n",
    "LangChain’s native driver for Ollama. Gives you ChatOllama (talk to local LLMs like llama3.2) and OllamaEmbeddings (create embeddings locally).\n",
    "\n",
    "- ollama\n",
    "Python client SDK for the Ollama server API.\n",
    "\n",
    "After installing\n",
    "- In notebooks, restart the kernel so new packages are picked up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "023b6ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.27)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\60175\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\60175\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\60175\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: langchain_community in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.29)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: langchain-ollama in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.8)\n",
      "Collecting langchain-ollama\n",
      "  Downloading langchain_ollama-0.3.10-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: ollama in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.11.9)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Downloading langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_community) (3.11.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_community) (2.11.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ollama) (0.27.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.17.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.27->ollama) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.27->ollama) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.27->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (24.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.0.0)\n",
      "Downloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.8/2.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 3.5 MB/s eta 0:00:00\n",
      "Downloading langchain_ollama-0.3.10-py3-none-any.whl (27 kB)\n",
      "Downloading langchain_core-0.3.79-py3-none-any.whl (449 kB)\n",
      "Installing collected packages: langchain-core, langchain-ollama, langchain_community\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.76\n",
      "    Uninstalling langchain-core-0.3.76:\n",
      "      Successfully uninstalled langchain-core-0.3.76\n",
      "  Attempting uninstall: langchain-ollama\n",
      "    Found existing installation: langchain-ollama 0.3.8\n",
      "    Uninstalling langchain-ollama-0.3.8:\n",
      "      Successfully uninstalled langchain-ollama-0.3.8\n",
      "  Attempting uninstall: langchain_community\n",
      "    Found existing installation: langchain-community 0.3.29\n",
      "    Uninstalling langchain-community-0.3.29:\n",
      "      Successfully uninstalled langchain-community-0.3.29\n",
      "Successfully installed langchain-core-0.3.79 langchain-ollama-0.3.10 langchain_community-0.3.31\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain langchain_community langchain-ollama ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9781d603",
   "metadata": {},
   "source": [
    "### Configure base URL for Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc4abef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama base URL: http://localhost:11434\n"
     ]
    }
   ],
   "source": [
    "import os, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Change if your Ollama runs elsewhere\n",
    "OLLAMA_BASE = os.getenv(\"OLLAMA_BASE\", \"http://localhost:11434\")\n",
    "print(\"Ollama base URL:\", OLLAMA_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95493417",
   "metadata": {},
   "source": [
    "### Interact with Ollama in Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28893442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model reply: Hello!\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "import os\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",   # or another local chat-capable model you've pulled\n",
    "    base_url=OLLAMA_BASE,\n",
    ")\n",
    " \n",
    "reply = llm.invoke(\"Say hello in one short sentence.\").content\n",
    "print(\"Model reply:\", reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fce7b7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready: llama3.2 @ http://localhost:11434\n",
      "---------------------------------------- \n",
      "\n",
      "User:  Why the sky is blue?\n",
      "System:  The sky appears blue because of a phenomenon called Rayleigh scattering, named after the British physicist Lord Rayleigh, who first described it in the late 19th century.\n",
      "\n",
      "Here's what happens:\n",
      "\n",
      "1. **Sunlight enters Earth's atmosphere**: When sunlight enters our atmosphere, it consists of a spectrum of colors, including all the colors of the visible light spectrum (red, orange, yellow, green, blue, indigo, and violet).\n",
      "2. **Light interacts with tiny molecules**: The sunlight encounters tiny molecules of gases such as nitrogen (N2) and oxygen (O2) in the atmosphere.\n",
      "3. **Scattering occurs**: These tiny molecules scatter the light in all directions, but they scatter shorter (blue) wavelengths more than longer (red) wavelengths. This is known as Rayleigh scattering.\n",
      "4. **Blue light is scattered in all directions**: As a result of this scattering, the blue light is distributed throughout the atmosphere, reaching our eyes from all parts of the sky.\n",
      "5. **Our eyes perceive the blue color**: When we look at the sky, our eyes detect the scattered blue light and interpret it as the color blue.\n",
      "\n",
      "The reason why the sky appears blue during the daytime and not at night is because:\n",
      "\n",
      "* At sunrise and sunset, the sun's rays have to travel through more of the Earth's atmosphere, which scatters the shorter wavelengths (like blue) even more, making the sky appear red or orange.\n",
      "* At night, the sun is below the horizon, and the scattered light from the atmosphere is no longer visible.\n",
      "\n",
      "So, in summary, the sky appears blue because of the scattering of sunlight by tiny molecules in the Earth's atmosphere, which preferentially scatters shorter wavelengths (like blue) more than longer wavelengths (like red).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Config\n",
    "OLLAMA_BASE = os.getenv(\"OLLAMA_BASE\", \"http://localhost:11434\")\n",
    "MODEL = \"llama3.2\"\n",
    "PROMPT = \"Why the sky is blue?\"\n",
    "\n",
    "# LLM (temperature=0 for reproducibility)\n",
    "llm = ChatOllama(model=MODEL, base_url=OLLAMA_BASE, temperature=0.0)\n",
    "print(\"Ready:\", MODEL, \"@\", OLLAMA_BASE)\n",
    "print(\"----------------------------------------\",\"\\n\")\n",
    "print(\"User: \", PROMPT)\n",
    "response = llm.invoke(PROMPT)\n",
    "print(\"System: \", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b948422",
   "metadata": {},
   "source": [
    "### Calculating token usage in Ollama\n",
    "\n",
    "1. Estimating Input Tokens:\n",
    "- Rule of Thumb: A common approximation for English text is that 1 token is roughly equal to 4 characters or ¾ of a word. So,input tokens can be estimated by counting characters and dividing by 4, or counting words and multiplying by ¾.\n",
    "\n",
    "2. Tracking Output Tokens and Performance:\n",
    "- Ollama API Response: When interacting with the Ollama API, the response payload (especially in non-streaming scenarios or at the end of a stream) will include fields like ```eval_count```(number of output tokens) and ```eval_duration``` (time taken to generate them).\n",
    "- Verbose Output: Run Ollama with the ```--verbose``` flag to see token counts and timing information after each message during execution.\n",
    "\n",
    "3. Measuring Tokens per Second:\n",
    "- Calculate tokens per second by dividing the ```eval_count``` (number of output tokens) by the ```eval_duration``` (time taken to generate them, typically in nanoseconds) from the Ollama API response. This gives you a measure of the model's generation speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab2b3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT: Why the sky is blue?\n",
      "chars: 20 | words: 5\n",
      "≈ tokens (chars/4): 5\n",
      "≈ tokens (words*0.75): 4\n"
     ]
    }
   ],
   "source": [
    "# 1. Estimating Input Tokens:\n",
    "# Rule of Thumb:\n",
    "\n",
    "def approx_tokens_chars(text: str) -> int:\n",
    "    # ~4 chars ≈ 1 token (very rough, English-centric)\n",
    "    return max(1, round(len(text) / 4))\n",
    "\n",
    "def approx_tokens_words(text: str) -> int:\n",
    "    # ~0.75 tokens per word (very rough)\n",
    "    return max(1, round(len(text.split()) * 0.75))\n",
    "\n",
    "print(\"PROMPT:\", PROMPT)\n",
    "print(\"chars:\", len(PROMPT), \"| words:\", len(PROMPT.split()))\n",
    "print(\"≈ tokens (chars/4):\", approx_tokens_chars(PROMPT))\n",
    "print(\"≈ tokens (words*0.75):\", approx_tokens_words(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9778e798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reply:\n",
      " The sky appears blue because of a phenomenon called Rayleigh scattering, named after the British physicist Lord Rayleigh, who first described it in the late 19th century.\n",
      "\n",
      "Here's what happens:\n",
      "\n",
      "1. **Sunlight enters Earth's atmosphere**: When sunlight enters our atmosphere, it consists of a spectrum of colors, including all the colors of the visible light spectrum (red, orange, yellow, green, blue, indigo, and violet).\n",
      "2. **Light interacts with tiny molecules**: The sunlight encounters tiny molecules of gases such as nitrogen (N2) and oxygen (O2) in the atmosphere.\n",
      "3. **Scattering occurs**: These tiny molecules scatter the light in all directions, but they scatter shorter (blue) wavelengths more than longer (red) wavelengths. This is known as Rayleigh scattering.\n",
      "4. **Blue light is scattered in all directions**: As a result of this scattering, the blue light is distributed throughout the atmosphere, reaching our eyes from all parts of the sky.\n",
      "5. **Our eyes perceive the blue color**: When we look at the sky, our eyes detect the scattered blue light and interpret it as the color blue.\n",
      "\n",
      "The reason why the sky appears blue during the daytime and not at night is because:\n",
      "\n",
      "* At sunrise and sunset, the sun's rays have to travel through more of the Earth's atmosphere, which scatters the shorter wavelengths (like blue) even more, making the sky appear red or orange.\n",
      "* At night, the sun is below the horizon, and the scattered light from the atmosphere is no longer visible.\n",
      "\n",
      "So, in summary, the sky appears blue because of the scattering of sunlight by tiny molecules in the Earth's atmosphere, which preferentially scatters shorter wavelengths (like blue) more than longer wavelengths (like red).\n",
      "\n",
      "--- Metadata ---\n",
      "prompt_eval_count: 31\n",
      "eval_count: 358\n",
      "eval_duration (ns): 5048364000\n",
      "total_duration (ns): 5135772600\n",
      "Tokens/sec (generation only): 70.91\n",
      "Tokens/sec (overall E2E): 69.71\n"
     ]
    }
   ],
   "source": [
    "# 2. Track output tokens & timings from LangChain → Ollama (non-streaming)\n",
    "\n",
    "print(\"Reply:\\n\", response.content)\n",
    "\n",
    "meta = getattr(response, \"response_metadata\", {}) or {}\n",
    "prompt_tokens = meta.get(\"prompt_eval_count\", 0)   # tokens in the input (as actually evaluated)\n",
    "output_tokens = meta.get(\"eval_count\", 0)          # tokens generated\n",
    "eval_duration_ns = meta.get(\"eval_duration\", 0)    # generation time (ns)\n",
    "total_duration_ns = meta.get(\"total_duration\", 0)  # end-to-end time (ns)\n",
    "\n",
    "print(\"\\n--- Metadata ---\")\n",
    "print(\"prompt_eval_count:\", prompt_tokens)\n",
    "print(\"eval_count:\", output_tokens)\n",
    "print(\"eval_duration (ns):\", eval_duration_ns)\n",
    "print(\"total_duration (ns):\", total_duration_ns)\n",
    "\n",
    "# 3. Compute tokens/sec (throughput) from metadata\n",
    "def tokens_per_second(eval_count: int, duration_ns: int) -> float:\n",
    "    return 0.0 if not duration_ns else eval_count / (duration_ns / 1e9)\n",
    "\n",
    "# Use the LangChain metadata\n",
    "print(\"Tokens/sec (generation only):\",\n",
    "      f\"{tokens_per_second(output_tokens, eval_duration_ns):.2f}\")\n",
    "\n",
    "print(\"Tokens/sec (overall E2E):\",\n",
    "      f\"{tokens_per_second(output_tokens, total_duration_ns):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0da0046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens (stream): 31\n",
      "Output tokens (stream): 358\n",
      "eval_duration (ns): 5893105900\n",
      "total_duration (ns): 6008688800\n"
     ]
    }
   ],
   "source": [
    "# 4. Streaming counts (final chunk has totals)\n",
    "chunks = list(llm.stream(PROMPT))\n",
    "final = chunks[-1]\n",
    "meta = getattr(final, \"response_metadata\", {}) or {}\n",
    "\n",
    "print(\"Prompt tokens (stream):\", meta.get(\"prompt_eval_count\", 0))\n",
    "print(\"Output tokens (stream):\", meta.get(\"eval_count\", 0))\n",
    "print(\"eval_duration (ns):\", meta.get(\"eval_duration\", 0))\n",
    "print(\"total_duration (ns):\", meta.get(\"total_duration\", 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e08be556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. CLI verbose (quick inspection), run in terminal:\n",
    "# ```ollama run llama3.2 --verbose```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7323715",
   "metadata": {},
   "source": [
    "CLI verbose (quick inspection), run in terminal:\n",
    "> ```ollama run llama3.2 --verbose```\n",
    "\n",
    "---\n",
    "Example Output:\n",
    "\n",
    "```\n",
    ">>> Why the sky is blue?\n",
    "The sky appears blue because of a phenomenon called Rayleigh scattering, named after the British physicist Lord Rayleigh, who first described it in the late 19th century.\n",
    "\n",
    "Here's what happens:\n",
    "\n",
    "1. When sunlight enters Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen (N2) and oxygen (O2).\n",
    "2. These molecules scatter the light in all directions, but they scatter shorter (blue) wavelengths more than longer (red) wavelengths.\n",
    "3. This is because the smaller molecules are more effective at scattering the shorter wavelengths.\n",
    "4. As a result, the blue light is scattered in all directions and reaches our eyes from all parts of the sky.\n",
    "5. Our eyes perceive this scattered blue light as the color of the sky.\n",
    "\n",
    "The reason we don't see the sky as red or violet (the colors that are scattered more than blue) is because our atmosphere scatters these longer wavelengths even less than it does the shorter blue wavelengths. This is why the sky\n",
    "typically appears blue during the day, especially in the direction of the sun.\n",
    "\n",
    "It's worth noting that the color of the sky can change under different conditions:\n",
    "\n",
    "* During sunrise and sunset, the light has to travel through more of the atmosphere, which scatters the shorter blue wavelengths even more, making the sky appear more red.\n",
    "* At high altitudes or during intense thunderstorms, the scattered light can be filtered by more particles in the air, changing the apparent color of the sky.\n",
    "* In areas with a lot of dust or pollution, the color of the sky can be altered due to additional scattering.\n",
    "\n",
    "So, that's why the sky is blue!\n",
    "\n",
    "total duration:       4.5327914s\n",
    "load duration:        38.6557ms\n",
    "prompt eval count:    31 token(s)\n",
    "prompt eval duration: 44.3904ms\n",
    "prompt eval rate:     698.35 tokens/s\n",
    "eval count:           330 token(s)\n",
    "eval duration:        4.4487313s\n",
    "eval rate:            74.18 tokens/s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd49ed0",
   "metadata": {},
   "source": [
    "### Parameters Tuning\n",
    "\n",
    "- temperature\n",
    "  - Lower temperature → safer, more predictable.\n",
    "  - Higher temperature → more creative/varied (and sometimes off-topic).\n",
    "- seed\n",
    "- top_p\n",
    "  - Smaller top_p → model samples from a smaller “nucleus” of probable tokens → safer, simpler language.\n",
    "  - Larger top_p → more diverse choices, slightly more creative output.\n",
    "- top_k\n",
    "  - Very small top_k may reduce vocabulary diversity; moderate values often fine.\n",
    "- Max output length(num_predict)\n",
    "  - Larger num_predict permits longer outputs (until the model naturally stops)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61a0159d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under moonlit skies so bright,\n",
      "A curious cat purrs with delight.\n",
      "She gazes up at lunar face,\n",
      "Her whiskers twitching in a wondrous space,\n",
      "In moonlight, her heart takes flight.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "import os\n",
    "\n",
    "# Tune parameters of LLM in Ollama\n",
    "llm_poem = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    ")\n",
    " \n",
    "PROMPT = \"Write a short (3–5 lines) poem about a cat that loves the moon.\"\n",
    "poem_demo = llm_poem.invoke(PROMPT).content\n",
    "print(poem_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4d5ba3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready: llama3.2 @ http://localhost:11434\n"
     ]
    }
   ],
   "source": [
    "import os, pandas as pd\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Config\n",
    "OLLAMA_BASE = os.getenv(\"OLLAMA_BASE\", \"http://localhost:11434\")\n",
    "MODEL = \"llama3.2\"\n",
    "PROMPT = \"Write a short (3–5 lines) poem about a cat that loves the moon.\"\n",
    "\n",
    "def run(prompt: str, **opts):\n",
    "    \"\"\"Invoke once with given options; return text + a few metrics for comparison.\"\"\"\n",
    "    llm = ChatOllama(model=MODEL, base_url=OLLAMA_BASE, **opts)\n",
    "    msg = llm.invoke(prompt)\n",
    "    meta = getattr(msg, \"response_metadata\", {}) or {}\n",
    "    text = (msg.content or \"\").strip()\n",
    "    # tokens/sec based on generation time\n",
    "    eval_ns = meta.get(\"eval_duration\", 0) or 0\n",
    "    tps = (meta.get(\"eval_count\", 0) / (eval_ns / 1e9)) if eval_ns else None\n",
    "    return text, {\n",
    "        \"prompt_tokens\": meta.get(\"prompt_eval_count\", 0),\n",
    "        \"out_tokens\": meta.get(\"eval_count\", 0),\n",
    "        \"tps_gen\": None if tps is None else round(tps, 2),\n",
    "    }\n",
    "\n",
    "def preview(text: str, n: int = 140) -> str:\n",
    "    s = (text or \"\").replace(\"\\n\", \" ⏎ \")\n",
    "    return s[:n] + (\"…\" if len(s) > n else \"\")\n",
    "\n",
    "print(\"Ready:\", MODEL, \"@\", OLLAMA_BASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3718a619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9d894 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9d894 td {\n",
       "  vertical-align: top;\n",
       "}\n",
       "#T_9d894_row0_col8, #T_9d894_row1_col8, #T_9d894_row2_col8, #T_9d894_row3_col8, #T_9d894_row4_col8, #T_9d894_row5_col8, #T_9d894_row6_col8, #T_9d894_row7_col8 {\n",
       "  white-space: pre-wrap;\n",
       "  font-family: monospace;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9d894\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9d894_level0_col0\" class=\"col_heading level0 col0\" >temperature</th>\n",
       "      <th id=\"T_9d894_level0_col1\" class=\"col_heading level0 col1\" >top_p</th>\n",
       "      <th id=\"T_9d894_level0_col2\" class=\"col_heading level0 col2\" >top_k</th>\n",
       "      <th id=\"T_9d894_level0_col3\" class=\"col_heading level0 col3\" >repeat_penalty</th>\n",
       "      <th id=\"T_9d894_level0_col4\" class=\"col_heading level0 col4\" >num_predict</th>\n",
       "      <th id=\"T_9d894_level0_col5\" class=\"col_heading level0 col5\" >seed</th>\n",
       "      <th id=\"T_9d894_level0_col6\" class=\"col_heading level0 col6\" >out_tokens</th>\n",
       "      <th id=\"T_9d894_level0_col7\" class=\"col_heading level0 col7\" >tps_gen</th>\n",
       "      <th id=\"T_9d894_level0_col8\" class=\"col_heading level0 col8\" >Poem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >label</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9d894_level0_row0\" class=\"row_heading level0 row0\" >baseline</th>\n",
       "      <td id=\"T_9d894_row0_col0\" class=\"data row0 col0\" >0.700000</td>\n",
       "      <td id=\"T_9d894_row0_col1\" class=\"data row0 col1\" >0.900000</td>\n",
       "      <td id=\"T_9d894_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "      <td id=\"T_9d894_row0_col3\" class=\"data row0 col3\" >None</td>\n",
       "      <td id=\"T_9d894_row0_col4\" class=\"data row0 col4\" >256</td>\n",
       "      <td id=\"T_9d894_row0_col5\" class=\"data row0 col5\" >42</td>\n",
       "      <td id=\"T_9d894_row0_col6\" class=\"data row0 col6\" >48</td>\n",
       "      <td id=\"T_9d894_row0_col7\" class=\"data row0 col7\" >53.370000</td>\n",
       "      <td id=\"T_9d894_row0_col8\" class=\"data row0 col8\" >Silver light upon her back,\n",
       "The moon's gentle beams, she'll not lack.\n",
       "She purrs with joy, in lunar delight,\n",
       "As night descends, and all is bright.\n",
       "Her feline heart beats to its gentle pace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d894_level0_row1\" class=\"row_heading level0 row1\" >temp=0.0</th>\n",
       "      <td id=\"T_9d894_row1_col0\" class=\"data row1 col0\" >0.200000</td>\n",
       "      <td id=\"T_9d894_row1_col1\" class=\"data row1 col1\" >0.900000</td>\n",
       "      <td id=\"T_9d894_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_9d894_row1_col3\" class=\"data row1 col3\" >None</td>\n",
       "      <td id=\"T_9d894_row1_col4\" class=\"data row1 col4\" >256</td>\n",
       "      <td id=\"T_9d894_row1_col5\" class=\"data row1 col5\" >42</td>\n",
       "      <td id=\"T_9d894_row1_col6\" class=\"data row1 col6\" >42</td>\n",
       "      <td id=\"T_9d894_row1_col7\" class=\"data row1 col7\" >78.780000</td>\n",
       "      <td id=\"T_9d894_row1_col8\" class=\"data row1 col8\" >Under lunar beams so bright,\n",
       "A feline form dances with delight.\n",
       "She purrs and stretches, eyes aglow,\n",
       "As moonlight whispers secrets low.\n",
       "In silvery light, she finds her home.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d894_level0_row2\" class=\"row_heading level0 row2\" >temp=1.2</th>\n",
       "      <td id=\"T_9d894_row2_col0\" class=\"data row2 col0\" >1.200000</td>\n",
       "      <td id=\"T_9d894_row2_col1\" class=\"data row2 col1\" >0.900000</td>\n",
       "      <td id=\"T_9d894_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "      <td id=\"T_9d894_row2_col3\" class=\"data row2 col3\" >None</td>\n",
       "      <td id=\"T_9d894_row2_col4\" class=\"data row2 col4\" >256</td>\n",
       "      <td id=\"T_9d894_row2_col5\" class=\"data row2 col5\" >42</td>\n",
       "      <td id=\"T_9d894_row2_col6\" class=\"data row2 col6\" >47</td>\n",
       "      <td id=\"T_9d894_row2_col7\" class=\"data row2 col7\" >73.880000</td>\n",
       "      <td id=\"T_9d894_row2_col8\" class=\"data row2 col8\" >Softly creeps the feline form,\n",
       "Drawn to moonbeams on the storm,\n",
       "Her eyes aglow with lunar light,\n",
       "A midnight dancer, lost in sight.\n",
       "In moonlit nights, she's free to roam.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d894_level0_row3\" class=\"row_heading level0 row3\" >seed=80</th>\n",
       "      <td id=\"T_9d894_row3_col0\" class=\"data row3 col0\" >0.700000</td>\n",
       "      <td id=\"T_9d894_row3_col1\" class=\"data row3 col1\" >0.900000</td>\n",
       "      <td id=\"T_9d894_row3_col2\" class=\"data row3 col2\" >nan</td>\n",
       "      <td id=\"T_9d894_row3_col3\" class=\"data row3 col3\" >None</td>\n",
       "      <td id=\"T_9d894_row3_col4\" class=\"data row3 col4\" >256</td>\n",
       "      <td id=\"T_9d894_row3_col5\" class=\"data row3 col5\" >80</td>\n",
       "      <td id=\"T_9d894_row3_col6\" class=\"data row3 col6\" >46</td>\n",
       "      <td id=\"T_9d894_row3_col7\" class=\"data row3 col7\" >77.760000</td>\n",
       "      <td id=\"T_9d894_row3_col8\" class=\"data row3 col8\" >Silver light, she purrs with glee,\n",
       "The moon above, her favorite spree.\n",
       "She stretches tall, and watches wide,\n",
       "Her feline heart, under lunar tide.\n",
       "In moonbeams bright, she dances free.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d894_level0_row4\" class=\"row_heading level0 row4\" >top_p=0.6</th>\n",
       "      <td id=\"T_9d894_row4_col0\" class=\"data row4 col0\" >0.700000</td>\n",
       "      <td id=\"T_9d894_row4_col1\" class=\"data row4 col1\" >0.600000</td>\n",
       "      <td id=\"T_9d894_row4_col2\" class=\"data row4 col2\" >nan</td>\n",
       "      <td id=\"T_9d894_row4_col3\" class=\"data row4 col3\" >None</td>\n",
       "      <td id=\"T_9d894_row4_col4\" class=\"data row4 col4\" >256</td>\n",
       "      <td id=\"T_9d894_row4_col5\" class=\"data row4 col5\" >42</td>\n",
       "      <td id=\"T_9d894_row4_col6\" class=\"data row4 col6\" >44</td>\n",
       "      <td id=\"T_9d894_row4_col7\" class=\"data row4 col7\" >79.610000</td>\n",
       "      <td id=\"T_9d894_row4_col8\" class=\"data row4 col8\" >Silver light upon her back,\n",
       "The moon's soft glow, she loves to track.\n",
       "In midnight skies, she dances free,\n",
       "A feline queen, beneath the sea.\n",
       "Her heart beats bright, with lunar delight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d894_level0_row5\" class=\"row_heading level0 row5\" >top_p=0.98</th>\n",
       "      <td id=\"T_9d894_row5_col0\" class=\"data row5 col0\" >0.700000</td>\n",
       "      <td id=\"T_9d894_row5_col1\" class=\"data row5 col1\" >0.980000</td>\n",
       "      <td id=\"T_9d894_row5_col2\" class=\"data row5 col2\" >nan</td>\n",
       "      <td id=\"T_9d894_row5_col3\" class=\"data row5 col3\" >None</td>\n",
       "      <td id=\"T_9d894_row5_col4\" class=\"data row5 col4\" >256</td>\n",
       "      <td id=\"T_9d894_row5_col5\" class=\"data row5 col5\" >42</td>\n",
       "      <td id=\"T_9d894_row5_col6\" class=\"data row5 col6\" >45</td>\n",
       "      <td id=\"T_9d894_row5_col7\" class=\"data row5 col7\" >77.820000</td>\n",
       "      <td id=\"T_9d894_row5_col8\" class=\"data row5 col8\" >Silver light upon her back,\n",
       "The moon's gentle beams, she'll gladly track.\n",
       "With eyes aglow like shining stone,\n",
       "She purrs and dances, all alone,\n",
       "Under the night sky, where love is home.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d894_level0_row6\" class=\"row_heading level0 row6\" >top_k=20</th>\n",
       "      <td id=\"T_9d894_row6_col0\" class=\"data row6 col0\" >0.700000</td>\n",
       "      <td id=\"T_9d894_row6_col1\" class=\"data row6 col1\" >0.900000</td>\n",
       "      <td id=\"T_9d894_row6_col2\" class=\"data row6 col2\" >20.000000</td>\n",
       "      <td id=\"T_9d894_row6_col3\" class=\"data row6 col3\" >None</td>\n",
       "      <td id=\"T_9d894_row6_col4\" class=\"data row6 col4\" >256</td>\n",
       "      <td id=\"T_9d894_row6_col5\" class=\"data row6 col5\" >42</td>\n",
       "      <td id=\"T_9d894_row6_col6\" class=\"data row6 col6\" >48</td>\n",
       "      <td id=\"T_9d894_row6_col7\" class=\"data row6 col7\" >82.770000</td>\n",
       "      <td id=\"T_9d894_row6_col8\" class=\"data row6 col8\" >Silver light upon her back,\n",
       "The moon's gentle beams, she'll not lack.\n",
       "She purrs with joy, in lunar delight,\n",
       "As night descends, and all is bright.\n",
       "Her feline heart beats to its gentle pace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9d894_level0_row7\" class=\"row_heading level0 row7\" >num_predict=47</th>\n",
       "      <td id=\"T_9d894_row7_col0\" class=\"data row7 col0\" >0.700000</td>\n",
       "      <td id=\"T_9d894_row7_col1\" class=\"data row7 col1\" >0.900000</td>\n",
       "      <td id=\"T_9d894_row7_col2\" class=\"data row7 col2\" >nan</td>\n",
       "      <td id=\"T_9d894_row7_col3\" class=\"data row7 col3\" >None</td>\n",
       "      <td id=\"T_9d894_row7_col4\" class=\"data row7 col4\" >47</td>\n",
       "      <td id=\"T_9d894_row7_col5\" class=\"data row7 col5\" >42</td>\n",
       "      <td id=\"T_9d894_row7_col6\" class=\"data row7 col6\" >47</td>\n",
       "      <td id=\"T_9d894_row7_col7\" class=\"data row7 col7\" >82.600000</td>\n",
       "      <td id=\"T_9d894_row7_col8\" class=\"data row7 col8\" >Silver light upon her back,\n",
       "The moon's gentle beams, she'll not lack.\n",
       "She purrs with joy, in lunar delight,\n",
       "As night descends, and all is bright.\n",
       "Her feline heart beats to its gentle pace.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1dd04147c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Different experiments\n",
    "EXPS = [\n",
    "    {\"label\": \"baseline\",              \"temperature\": 0.7, \"top_p\": 0.9,  \"num_predict\": 256,  \"seed\": 42},\n",
    "    {\"label\": \"temp=0.0\",              \"temperature\": 0.2, \"top_p\": 0.9,  \"num_predict\": 256, \"seed\": 42},\n",
    "    {\"label\": \"temp=1.2\",              \"temperature\": 1.2, \"top_p\": 0.9,  \"num_predict\": 256, \"seed\": 42},\n",
    "    {\"label\": \"seed=80\",              \"temperature\": 0.7, \"top_p\": 0.9,  \"num_predict\": 256, \"seed\": 80},\n",
    "    {\"label\": \"top_p=0.6\",             \"temperature\": 0.7, \"top_p\": 0.6,  \"num_predict\": 256, \"seed\": 42},\n",
    "    {\"label\": \"top_p=0.98\",            \"temperature\": 0.7, \"top_p\": 0.98, \"num_predict\": 256, \"seed\": 42},\n",
    "    {\"label\": \"top_k=20\",              \"temperature\": 0.7, \"top_p\": 0.9,  \"top_k\": 20,        \"num_predict\": 256, \"seed\": 42},\n",
    "    {\"label\": \"num_predict=47\",        \"temperature\": 0.7, \"top_p\": 0.9,  \"num_predict\": 47,  \"seed\": 42},\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for exp in EXPS:\n",
    "    opts = {k: v for k, v in exp.items() if k != \"label\"}\n",
    "    text, m = run(PROMPT, **opts)\n",
    "    rows.append({\n",
    "        \"label\": exp[\"label\"],\n",
    "        \"temperature\": opts.get(\"temperature\"),\n",
    "        \"top_p\": opts.get(\"top_p\"),\n",
    "        \"top_k\": opts.get(\"top_k\"),\n",
    "        \"repeat_penalty\": opts.get(\"repeat_penalty\"),\n",
    "        \"num_predict\": opts.get(\"num_predict\"),\n",
    "        \"seed\": opts.get(\"seed\"),\n",
    "        \"out_tokens\": m[\"out_tokens\"],\n",
    "        \"tps_gen\": m[\"tps_gen\"],\n",
    "        \"Poem\": text,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).set_index(\"label\")\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "styled = (\n",
    "    df.style\n",
    "      .set_properties(subset=['Poem'], **{\n",
    "          'white-space': 'pre-wrap',   \n",
    "          'font-family': 'monospace',  \n",
    "      })\n",
    "      .set_table_styles([\n",
    "          {'selector': 'th', 'props': [('text-align', 'left')]},\n",
    "          {'selector': 'td', 'props': [('vertical-align', 'top')]}\n",
    "      ])\n",
    ")\n",
    "\n",
    "display(styled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c7807",
   "metadata": {},
   "source": [
    "### Prompting \n",
    "\n",
    "There're a few prompt styles: zero-shot, few-shot, role + constraints, and structured JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd8f69fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an explanation of Artificial Intelligence (AI) in 3 simple bullet points:\n",
      "\n",
      "• **AI is like super smart computers**: AI refers to computer systems that can think and learn like humans. These computers use complex algorithms and data to make decisions, solve problems, and even create new things.\n",
      "\n",
      "• **AI learns from data and experiences**: Unlike humans, AI doesn't start with a blank slate. It's trained on vast amounts of data, which helps it learn patterns, recognize objects, and improve its performance over time. This learning process is called machine learning.\n",
      "\n",
      "• **AI can perform tasks that require human intelligence**: With advancements in AI, computers can now perform tasks that typically require human intelligence, such as recognizing faces, understanding natural language, playing games, or even driving cars. However, it's essential to note that AI still has limitations and requires careful design, training, and testing to ensure its performance is reliable and trustworthy.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\", base_url=OLLAMA_BASE, temperature=0.3)\n",
    "\n",
    "prompt = \"\"\"You are a helpful assistant.\n",
    "Explain the concept of Artificial Intelligence in 3 bullet points, plain language.\"\"\"\n",
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b969cda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey there, little buddy! So, you know how we can teach computers to do things like play games and show pictures? Well, AI is like a super smart computer that can learn and do even more cool things on its own!\n",
      "\n",
      "Imagine you have a toy robot friend, and you teach it to recognize different toys. At first, it might not be very good at it, but the more you play with it and tell it what's what, the better it gets! That's kind of like how AI learns - by looking at lots of examples and getting better and better.\n",
      "\n",
      "But here's the really cool part: AI can even make up its own games or stories! It's like having a magic friend who can create new adventures just for you. And because it's so smart, it can help us solve problems and make our lives easier.\n",
      "\n",
      "So, AI is like a super smart computer that can learn, play, and even be creative - isn't that awesome?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "msgs = [\n",
    "    SystemMessage(content=\"You are a precise technical writer. Use short, formal sentences.\"),\n",
    "    HumanMessage(content=\"Explain AI to a 5-year-old in a playful tone.\"),\n",
    "]\n",
    "print(llm.invoke(msgs).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c9b693f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence refers to the development of computer systems that can perform tasks that typically require human intelligence, such as learning, problem-solving, and decision-making.\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = \"\"\"\n",
    "You are a concise assistant. Answer with one sentence.\n",
    "\n",
    "Q: What is tokenization in NLP?\n",
    "A: Converting text into smaller units (tokens) for processing.\n",
    "\n",
    "Q: What is a vector embedding?\n",
    "A: A numeric representation of text that captures semantic meaning.\n",
    "\n",
    "Q: What is Artificial Intelligence?\n",
    "A:\n",
    "\"\"\".strip()\n",
    "\n",
    "print(llm.invoke(few_shot_prompt).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e02f69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Artificial Intelligence (AI) refers to the development of computer systems that simulate human intelligence.\n",
      "• AI involves the creation of algorithms and models that can perform tasks autonomously.\n",
      "• The goal of AI is to enable machines to think, learn, and act like humans.\n"
     ]
    }
   ],
   "source": [
    "role_prompt = \"\"\"\n",
    "## SYSTEM\n",
    "You are a technical writing assistant. Be precise and avoid fluff.\n",
    "\n",
    "## TASK\n",
    "Summarize the definition of Artificial Intelligence.\n",
    "\n",
    "## REQUIREMENTS\n",
    "- 3 bullet points\n",
    "- Each bullet ≤ 15 words\n",
    "- No marketing language\n",
    "\"\"\".strip()\n",
    "\n",
    "print(llm.invoke(role_prompt).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f930f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output:\n",
      " Here is the JSON object:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"title\": \"Definition of Artificial Intelligence\",\n",
      "    \"summary\": \"Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions.\",\n",
      "    \"keywords\": [\n",
      "        \"Machine Learning\",\n",
      "        \"Deep Learning\",\n",
      "        \"Natural Language Processing\"\n",
      "    ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Structured JSON output\n",
    "\n",
    "import json, re\n",
    "\n",
    "json_prompt = \"\"\"\n",
    "Return a JSON object with keys: \"title\", \"summary\", and \"keywords\".\n",
    "Topic: \"Definition of Artificial Intelligence\"\n",
    "Keep summary < 40 words. keywords = array of 3–5 short items.\n",
    "\"\"\".strip()\n",
    "\n",
    "raw = llm.invoke(json_prompt).content\n",
    "print(\"Raw output:\\n\", raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7203d587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRAFT:\n",
      " Artificial Intelligence (AI) refers to computer systems that can think and learn like humans, using algorithms and data to make decisions and perform tasks automatically. AI can be used for a wide range of applications, from virtual assistants like Siri and Alexa to self-driving cars and medical diagnosis tools. \n",
      "\n",
      "FINAL:\n",
      " Computer systems that mimic human thought and learning use algorithms and data to make decisions and perform tasks automatically. Examples include virtual assistants and self-driving cars.\n"
     ]
    }
   ],
   "source": [
    "draft = llm.invoke(\"Define AI in 2 sentences, plain language.\").content\n",
    "\n",
    "critique_prompt = f\"\"\"\n",
    "You will refine the draft to meet ALL constraints:\n",
    "- ≤ 35 words total\n",
    "- No marketing language\n",
    "- Avoid buzzwords\n",
    "\n",
    "DRAFT:\n",
    "{draft}\n",
    "\n",
    "Return the FINAL version only.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"DRAFT:\\n\", draft, \"\\n\")\n",
    "print(\"FINAL:\\n\", llm.invoke(critique_prompt).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36256e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_04b03 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_04b03 td {\n",
       "  vertical-align: top;\n",
       "}\n",
       "#T_04b03_row0_col2, #T_04b03_row1_col2, #T_04b03_row2_col2, #T_04b03_row3_col2 {\n",
       "  white-space: pre-wrap;\n",
       "  font-family: monospace;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_04b03\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_04b03_level0_col0\" class=\"col_heading level0 col0\" >method</th>\n",
       "      <th id=\"T_04b03_level0_col1\" class=\"col_heading level0 col1\" >prompt</th>\n",
       "      <th id=\"T_04b03_level0_col2\" class=\"col_heading level0 col2\" >output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_04b03_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_04b03_row0_col0\" class=\"data row0 col0\" >Answer-only</td>\n",
       "      <td id=\"T_04b03_row0_col1\" class=\"data row0 col1\" >Solve the problem and output ONLY the final integer answer.\n",
       "No units. No steps. No explanation.\n",
       "\n",
       "Problem: What is the sum of the first 10 positive integers?</td>\n",
       "      <td id=\"T_04b03_row0_col2\" class=\"data row0 col2\" >55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04b03_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_04b03_row1_col0\" class=\"data row1 col0\" >Brief rationale</td>\n",
       "      <td id=\"T_04b03_row1_col1\" class=\"data row1 col1\" >Solve the problem. Provide:\n",
       "1) Brief rationale in ≤ 15 words\n",
       "2) Final answer on a new line as: ANSWER: <number>\n",
       "\n",
       "Problem: What is the sum of the first 10 positive integers?</td>\n",
       "      <td id=\"T_04b03_row1_col2\" class=\"data row1 col2\" >Rationale: This is an arithmetic series sum calculation.\n",
       "\n",
       "ANSWER: 55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04b03_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_04b03_row2_col0\" class=\"data row2 col0\" >Plan → Answer</td>\n",
       "      <td id=\"T_04b03_row2_col1\" class=\"data row2 col1\" >Create a very short 3-step plan (each ≤ 5 words) to solve:\n",
       "\n",
       "What is the sum of the first 10 positive integers?\n",
       "\n",
       "Then on a new line, output final answer as:\n",
       "ANSWER: <number>\n",
       "\n",
       "Do not show intermediate calculations.</td>\n",
       "      <td id=\"T_04b03_row2_col2\" class=\"data row2 col2\" >Step 1: List the numbers\n",
       "2. Add them together quickly\n",
       "3. Calculate total sum\n",
       "\n",
       "ANSWER: 55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04b03_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_04b03_row3_col0\" class=\"data row3 col0\" >Self-Consistency (majority)</td>\n",
       "      <td id=\"T_04b03_row3_col1\" class=\"data row3 col1\" >Solve the problem and output ONLY the final integer answer.\n",
       "No units. No steps. No explanation.\n",
       "\n",
       "Problem: What is the sum of the first 10 positive integers?\n",
       "\n",
       "(Self-consistency: 7 samples, temp=0.8, seeds=1..7)</td>\n",
       "      <td id=\"T_04b03_row3_col2\" class=\"data row3 col2\" >55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1dd069da180>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-Consistency vote distribution: 55×5, 1×1, 10×1\n"
     ]
    }
   ],
   "source": [
    "# Example: Math problem solving with different prompt styles + self-consistency\n",
    "\n",
    "import os, re, collections, pandas as pd\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Config\n",
    "OLLAMA_BASE = os.getenv(\"OLLAMA_BASE\", \"http://localhost:11434\")\n",
    "MODEL = \"llama3.2\"\n",
    "QUESTION = \"What is the sum of the first 10 positive integers?\"\n",
    "\n",
    "# LLMs (tweak temps if you like)\n",
    "llm        = ChatOllama(model=MODEL, base_url=OLLAMA_BASE, temperature=0.2)\n",
    "llm_brief  = ChatOllama(model=MODEL, base_url=OLLAMA_BASE, temperature=0.3)\n",
    "llm_plan   = ChatOllama(model=MODEL, base_url=OLLAMA_BASE, temperature=0.4)\n",
    "\n",
    "# Prompts\n",
    "prompt_answer_only = f\"\"\"\n",
    "Solve the problem and output ONLY the final integer answer.\n",
    "No units. No steps. No explanation.\n",
    "\n",
    "Problem: {QUESTION}\n",
    "\"\"\".strip()\n",
    "\n",
    "# Brief rationale\n",
    "prompt_brief = f\"\"\"\n",
    "Solve the problem. Provide:\n",
    "1) Brief rationale in ≤ 15 words\n",
    "2) Final answer on a new line as: ANSWER: <number>\n",
    "\n",
    "Problem: {QUESTION}\n",
    "\"\"\".strip()\n",
    "\n",
    "# Plan\n",
    "prompt_plan = f\"\"\"\n",
    "Create a very short 3-step plan (each ≤ 5 words) to solve:\n",
    "\n",
    "{QUESTION}\n",
    "\n",
    "Then on a new line, output final answer as:\n",
    "ANSWER: <number>\n",
    "\n",
    "Do not show intermediate calculations.\n",
    "\"\"\".strip()\n",
    "\n",
    "# Self-consistency helper\n",
    "def answer_only_sample(q, seed=None, temp=0.8):\n",
    "    llm_sc = ChatOllama(model=MODEL, base_url=OLLAMA_BASE, temperature=temp, seed=seed)\n",
    "    m = llm_sc.invoke(f\"Solve and output ONLY the final integer answer.\\n\\nProblem: {q}\")\n",
    "    txt = (m.content or \"\").strip()\n",
    "    nums = re.findall(r\"-?\\d+\", txt)\n",
    "    return nums[0] if nums else txt\n",
    "\n",
    "# Gather outputs\n",
    "ans_only = llm.invoke(prompt_answer_only).content.strip()\n",
    "brief    = llm_brief.invoke(prompt_brief).content.strip()\n",
    "plan     = llm_plan.invoke(prompt_plan).content.strip()\n",
    "\n",
    "# Self-consistency majority vote\n",
    "answers  = [answer_only_sample(QUESTION, seed=s) for s in [1,2,3,4,5,6,7]]\n",
    "counter  = collections.Counter(answers)\n",
    "majority = counter.most_common(1)[0][0]\n",
    "\n",
    "top_counts = counter.most_common()\n",
    "top_counts_str = \", \".join(f\"{ans}×{cnt}\" for ans, cnt in top_counts)\n",
    "sc_note = \"(Self-consistency: 7 samples, temp=0.8, seeds=1..7)\"\n",
    "sc_prompt_text = prompt_answer_only + \"\\n\\n\" + sc_note\n",
    "\n",
    "\n",
    "# Build table\n",
    "rows = [\n",
    "    {\"method\": \"Answer-only\", \"prompt\": prompt_answer_only, \"output\": ans_only},\n",
    "    {\"method\": \"Brief rationale\", \"prompt\": prompt_brief, \"output\": brief},\n",
    "    {\"method\": \"Plan → Answer\", \"prompt\": prompt_plan, \"output\": plan},\n",
    "    {\"method\": \"Self-Consistency (majority)\", \"prompt\": sc_prompt_text, \"output\": majority},\n",
    "]\n",
    "\n",
    "df_prompt = pd.DataFrame(rows)\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "styled_prompt_table = (\n",
    "    df_prompt.style\n",
    "      .set_properties(subset=['output'], **{\n",
    "          'white-space': 'pre-wrap', \n",
    "          'font-family': 'monospace', \n",
    "      })\n",
    "      .set_table_styles([\n",
    "          {'selector': 'th', 'props': [('text-align', 'left')]},\n",
    "          {'selector': 'td', 'props': [('vertical-align', 'top')]},\n",
    "      ])\n",
    ")\n",
    "display(styled_prompt_table)\n",
    "\n",
    "print(\"Self-Consistency vote distribution:\", top_counts_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217339be",
   "metadata": {},
   "source": [
    "---\n",
    "### Build Simple Chatbot Interface:\n",
    "\n",
    "- Streamlit\n",
    "- Gradio\n",
    "- Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afcdfa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.44.0)\n",
      "Requirement already satisfied: gradio in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (5.9.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.2.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.3.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.28.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (15.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.32.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (4.15.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (4.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (3.1.41)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (6.4)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (4.7.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.115.4)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.5.2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (1.5.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.27.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.35.1)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (3.10.11)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.11.9)\n",
      "Requirement already satisfied: pydub in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.8.4)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.41.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.12.5)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.25.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio-client==1.5.2->gradio) (2024.9.0)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio-client==1.5.2->gradio) (13.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2023.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.0->gradio) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (1.26.18)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.17.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\60175\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\60175\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\60175\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install streamlit gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc5f3df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, gradio as gr\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "OLLAMA_BASE = os.getenv(\"OLLAMA_BASE\", \"http://localhost:11434\")\n",
    "llm = ChatOllama(model=\"llama3.2\", base_url=OLLAMA_BASE, temperature=0.2)\n",
    "\n",
    "def reply(message, history): \n",
    "    out = llm.invoke(message).content\n",
    "    return out\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=reply,\n",
    "    title=\"Simple Chatbot (Gradio + Ollama)\",\n",
    "    description=\"Type a message and get a response from a local model.\",\n",
    ")\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
