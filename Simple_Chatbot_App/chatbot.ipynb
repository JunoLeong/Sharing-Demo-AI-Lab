{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ee09b8e",
   "metadata": {},
   "source": [
    "# Demo: Local LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaead475",
   "metadata": {},
   "source": [
    "## Ollama and Langchain\n",
    "\n",
    "### What is Ollama?\n",
    "- A local LLM runtime to run models (Llama, Mistral, Qwen, Phi, etc.) on local machine with simple commands.\n",
    "- Pull & run models:\n",
    "  ```bash\n",
    "    ollama serve\n",
    "    ollama pull llama3.2\n",
    "    ollama run llama3.2\n",
    "    ``` \n",
    "- Exposes an HTTP API (default http://localhost:11434) for chat, embeddings, and model management.\n",
    "- Great for privacy, offline work, reproducible demos, and avoiding cloud costs.\n",
    "- **Website:** [ollama.com](https://ollama.com)\n",
    "\n",
    "---\n",
    "### What is Langchain?\n",
    "- A Python framework to build LLM apps by composing blocks:\n",
    "- Models (ChatModel, LLM), Embeddings, Document Loaders, TextSplitters, VectorStores, and Chains/Runnables.\n",
    "- Providing unified interface for different providers (local or cloud), plus utilities for RAG, tools, and orchestration.\n",
    "- Building blocks to turn that into apps\n",
    "- **Docs:** [LangChain Python Docs](https://docs.langchain.com/oss/python/langchain/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737865c8",
   "metadata": {},
   "source": [
    "## Set Up Environemnt\n",
    "\n",
    "Download the necessary packages for building RAG pipelines\n",
    "\n",
    "- langchain\n",
    "Core framework for building LLM apps (chains, prompts, runnables). You use it for text splitters, message types, and composing the RAG flow.\n",
    "\n",
    "- langchain_community\n",
    "Community-maintained integrations that were split out of langchain. Includes loaders (e.g., PyPDFLoader) and many third-party connectors you call in your code.\n",
    "\n",
    "- langchain-ollama\n",
    "LangChain’s native driver for Ollama. Gives you ChatOllama (talk to local LLMs like llama3.2) and OllamaEmbeddings (create embeddings locally).\n",
    "\n",
    "- ollama\n",
    "Python client SDK for the Ollama server API.\n",
    "\n",
    "After installing\n",
    "- In notebooks, restart the kernel so new packages are picked up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "023b6ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.29)\n",
      "Requirement already satisfied: langchain-ollama in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.8)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: ollama in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.10.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_community) (3.11.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_community) (2.11.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ollama) (0.27.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.17.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.27->ollama) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.27->ollama) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.27->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\60175\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\60175\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\60175\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain_community langchain-ollama ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9781d603",
   "metadata": {},
   "source": [
    "### Configure base URL for Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc4abef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama base URL: http://localhost:11434\n"
     ]
    }
   ],
   "source": [
    "import os, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Change if your Ollama runs elsewhere\n",
    "OLLAMA_BASE = os.getenv(\"OLLAMA_BASE\", \"http://localhost:11434\")\n",
    "print(\"Ollama base URL:\", OLLAMA_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95493417",
   "metadata": {},
   "source": [
    "### Interact with Ollama in Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28893442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model reply: Hello!\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "import os\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",   # or another local chat-capable model you've pulled\n",
    "    base_url=OLLAMA_BASE,\n",
    ")\n",
    " \n",
    "reply = llm.invoke(\"Say hello in one short sentence.\").content\n",
    "print(\"Model reply:\", reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fce7b7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready: llama3.2 @ http://localhost:11434\n",
      "---------------------------------------- \n",
      "\n",
      "User:  Why the sky is blue?\n",
      "System:  The sky appears blue because of a phenomenon called Rayleigh scattering, named after the British physicist Lord Rayleigh, who first described it in the late 19th century.\n",
      "\n",
      "Here's what happens:\n",
      "\n",
      "1. **Sunlight enters Earth's atmosphere**: When sunlight enters our atmosphere, it consists of a spectrum of colors, including all the colors of the visible light spectrum (red, orange, yellow, green, blue, indigo, and violet).\n",
      "2. **Light interacts with tiny molecules**: The sunlight encounters tiny molecules of gases such as nitrogen (N2) and oxygen (O2) in the atmosphere.\n",
      "3. **Scattering occurs**: These tiny molecules scatter the light in all directions, but they scatter shorter (blue) wavelengths more than longer (red) wavelengths. This is known as Rayleigh scattering.\n",
      "4. **Blue light is scattered in all directions**: As a result of this scattering, the blue light is distributed throughout the atmosphere, reaching our eyes from all parts of the sky.\n",
      "5. **Our eyes perceive the blue color**: When we look at the sky, our eyes detect the scattered blue light and interpret it as the color blue.\n",
      "\n",
      "The reason why the sky appears more blue during the daytime than at sunrise or sunset is because the sun's rays have to travel through more of the atmosphere to reach us, which scatters even more of the shorter wavelengths (like blue). At sunrise and sunset, the sun's rays have to travel through less of the atmosphere, so there's less scattering, and the sky appears more red.\n",
      "\n",
      "So, in summary, the sky is blue because of the scattering of sunlight by tiny molecules in the Earth's atmosphere, which preferentially scatters shorter wavelengths (like blue) over longer wavelengths (like red).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Config\n",
    "OLLAMA_BASE = os.getenv(\"OLLAMA_BASE\", \"http://localhost:11434\")\n",
    "MODEL = \"llama3.2\"\n",
    "PROMPT = \"Why the sky is blue?\"\n",
    "\n",
    "# LLM (temperature=0 for reproducibility)\n",
    "llm = ChatOllama(model=MODEL, base_url=OLLAMA_BASE, temperature=0.0)\n",
    "print(\"Ready:\", MODEL, \"@\", OLLAMA_BASE)\n",
    "print(\"----------------------------------------\",\"\\n\")\n",
    "print(\"User: \", PROMPT)\n",
    "response = llm.invoke(PROMPT)\n",
    "print(\"System: \", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b948422",
   "metadata": {},
   "source": [
    "### Calculating token usage in Ollama\n",
    "\n",
    "1. Estimating Input Tokens:\n",
    "- Rule of Thumb: A common approximation for English text is that 1 token is roughly equal to 4 characters or ¾ of a word. So,input tokens can be estimated by counting characters and dividing by 4, or counting words and multiplying by ¾.\n",
    "\n",
    "2. Tracking Output Tokens and Performance:\n",
    "- Ollama API Response: When interacting with the Ollama API, the response payload (especially in non-streaming scenarios or at the end of a stream) will include fields like ```eval_count```(number of output tokens) and ```eval_duration``` (time taken to generate them).\n",
    "- Verbose Output: Run Ollama with the ```--verbose``` flag to see token counts and timing information after each message during execution.\n",
    "\n",
    "3. Measuring Tokens per Second:\n",
    "- Calculate tokens per second by dividing the ```eval_count``` (number of output tokens) by the ```eval_duration``` (time taken to generate them, typically in nanoseconds) from the Ollama API response. This gives you a measure of the model's generation speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab2b3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT: Why the sky is blue?\n",
      "chars: 20 | words: 5\n",
      "≈ tokens (chars/4): 5\n",
      "≈ tokens (words*0.75): 4\n"
     ]
    }
   ],
   "source": [
    "# 1. Estimating Input Tokens:\n",
    "# Rule of Thumb:\n",
    "\n",
    "def approx_tokens_chars(text: str) -> int:\n",
    "    # ~4 chars ≈ 1 token (very rough, English-centric)\n",
    "    return max(1, round(len(text) / 4))\n",
    "\n",
    "def approx_tokens_words(text: str) -> int:\n",
    "    # ~0.75 tokens per word (very rough)\n",
    "    return max(1, round(len(text.split()) * 0.75))\n",
    "\n",
    "print(\"PROMPT:\", PROMPT)\n",
    "print(\"chars:\", len(PROMPT), \"| words:\", len(PROMPT.split()))\n",
    "print(\"≈ tokens (chars/4):\", approx_tokens_chars(PROMPT))\n",
    "print(\"≈ tokens (words*0.75):\", approx_tokens_words(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9778e798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reply:\n",
      " The sky appears blue because of a phenomenon called Rayleigh scattering, named after the British physicist Lord Rayleigh, who first described it in the late 19th century.\n",
      "\n",
      "Here's what happens:\n",
      "\n",
      "1. **Sunlight enters Earth's atmosphere**: When sunlight enters our atmosphere, it consists of a spectrum of colors, including all the colors of the visible light spectrum (red, orange, yellow, green, blue, indigo, and violet).\n",
      "2. **Light interacts with tiny molecules**: The sunlight encounters tiny molecules of gases such as nitrogen (N2) and oxygen (O2) in the atmosphere.\n",
      "3. **Scattering occurs**: These tiny molecules scatter the light in all directions, but they scatter shorter (blue) wavelengths more than longer (red) wavelengths. This is known as Rayleigh scattering.\n",
      "4. **Blue light is scattered in all directions**: As a result of this scattering, the blue light is distributed throughout the atmosphere, reaching our eyes from all parts of the sky.\n",
      "5. **Our eyes perceive the blue color**: When we look at the sky, our eyes detect the scattered blue light and interpret it as the color blue.\n",
      "\n",
      "The reason why the sky appears more blue during the daytime than at sunrise or sunset is because the sun's rays have to travel through more of the atmosphere to reach us, which scatters even more of the shorter wavelengths (like blue). At sunrise and sunset, the sun's rays have to travel through less of the atmosphere, so there's less scattering, and the sky appears more red.\n",
      "\n",
      "So, in summary, the sky is blue because of the scattering of sunlight by tiny molecules in the Earth's atmosphere, which preferentially scatters shorter wavelengths (like blue) over longer wavelengths (like red).\n",
      "\n",
      "--- Metadata ---\n",
      "prompt_eval_count: 31\n",
      "eval_count: 353\n",
      "eval_duration (ns): 4609871200\n",
      "total_duration (ns): 4708219300\n",
      "Tokens/sec (generation only): 76.57\n",
      "Tokens/sec (overall E2E): 74.98\n"
     ]
    }
   ],
   "source": [
    "# 2. Track output tokens & timings from LangChain → Ollama (non-streaming)\n",
    "\n",
    "print(\"Reply:\\n\", response.content)\n",
    "\n",
    "meta = getattr(response, \"response_metadata\", {}) or {}\n",
    "prompt_tokens = meta.get(\"prompt_eval_count\", 0)   # tokens in the input (as actually evaluated)\n",
    "output_tokens = meta.get(\"eval_count\", 0)          # tokens generated\n",
    "eval_duration_ns = meta.get(\"eval_duration\", 0)    # generation time (ns)\n",
    "total_duration_ns = meta.get(\"total_duration\", 0)  # end-to-end time (ns)\n",
    "\n",
    "print(\"\\n--- Metadata ---\")\n",
    "print(\"prompt_eval_count:\", prompt_tokens)\n",
    "print(\"eval_count:\", output_tokens)\n",
    "print(\"eval_duration (ns):\", eval_duration_ns)\n",
    "print(\"total_duration (ns):\", total_duration_ns)\n",
    "\n",
    "# 3. Compute tokens/sec (throughput) from metadata\n",
    "def tokens_per_second(eval_count: int, duration_ns: int) -> float:\n",
    "    return 0.0 if not duration_ns else eval_count / (duration_ns / 1e9)\n",
    "\n",
    "# Use the LangChain metadata\n",
    "print(\"Tokens/sec (generation only):\",\n",
    "      f\"{tokens_per_second(output_tokens, eval_duration_ns):.2f}\")\n",
    "\n",
    "print(\"Tokens/sec (overall E2E):\",\n",
    "      f\"{tokens_per_second(output_tokens, total_duration_ns):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0da0046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens (stream): 31\n",
      "Output tokens (stream): 347\n",
      "eval_duration (ns): 4451618100\n",
      "total_duration (ns): 9618820400\n"
     ]
    }
   ],
   "source": [
    "# 4. Streaming counts (final chunk has totals)\n",
    "chunks = list(llm.stream(PROMPT))\n",
    "final = chunks[-1]\n",
    "meta = getattr(final, \"response_metadata\", {}) or {}\n",
    "\n",
    "print(\"Prompt tokens (stream):\", meta.get(\"prompt_eval_count\", 0))\n",
    "print(\"Output tokens (stream):\", meta.get(\"eval_count\", 0))\n",
    "print(\"eval_duration (ns):\", meta.get(\"eval_duration\", 0))\n",
    "print(\"total_duration (ns):\", meta.get(\"total_duration\", 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e08be556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. CLI verbose (quick inspection), run in terminal:\n",
    "# ```ollama run llama3.2 --verbose```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7323715",
   "metadata": {},
   "source": [
    "CLI verbose (quick inspection), run in terminal:\n",
    "> ```ollama run llama3.2 --verbose```\n",
    "\n",
    "---\n",
    "Example Output:\n",
    "\n",
    "```\n",
    ">>> Why the sky is blue?\n",
    "The sky appears blue because of a phenomenon called Rayleigh scattering, named after the British physicist Lord Rayleigh, who first described it in the late 19th century.\n",
    "\n",
    "Here's what happens:\n",
    "\n",
    "1. When sunlight enters Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen (N2) and oxygen (O2).\n",
    "2. These molecules scatter the light in all directions, but they scatter shorter (blue) wavelengths more than longer (red) wavelengths.\n",
    "3. This is because the smaller molecules are more effective at scattering the shorter wavelengths.\n",
    "4. As a result, the blue light is scattered in all directions and reaches our eyes from all parts of the sky.\n",
    "5. Our eyes perceive this scattered blue light as the color of the sky.\n",
    "\n",
    "The reason we don't see the sky as red or violet (the colors that are scattered more than blue) is because our atmosphere scatters these longer wavelengths even less than it does the shorter blue wavelengths. This is why the sky\n",
    "typically appears blue during the day, especially in the direction of the sun.\n",
    "\n",
    "It's worth noting that the color of the sky can change under different conditions:\n",
    "\n",
    "* During sunrise and sunset, the light has to travel through more of the atmosphere, which scatters the shorter blue wavelengths even more, making the sky appear more red.\n",
    "* At high altitudes or during intense thunderstorms, the scattered light can be filtered by more particles in the air, changing the apparent color of the sky.\n",
    "* In areas with a lot of dust or pollution, the color of the sky can be altered due to additional scattering.\n",
    "\n",
    "So, that's why the sky is blue!\n",
    "\n",
    "total duration:       4.5327914s\n",
    "load duration:        38.6557ms\n",
    "prompt eval count:    31 token(s)\n",
    "prompt eval duration: 44.3904ms\n",
    "prompt eval rate:     698.35 tokens/s\n",
    "eval count:           330 token(s)\n",
    "eval duration:        4.4487313s\n",
    "eval rate:            74.18 tokens/s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd49ed0",
   "metadata": {},
   "source": [
    "### Parameters Tuning\n",
    "\n",
    "- temperature\n",
    "  - Lower temperature → safer, more predictable.\n",
    "  - Higher temperature → more creative/varied (and sometimes off-topic).\n",
    "- seed\n",
    "- top_p\n",
    "  - Smaller top_p → model samples from a smaller “nucleus” of probable tokens → safer, simpler language.\n",
    "  - Larger top_p → more diverse choices, slightly more creative output.\n",
    "- top_k\n",
    "  - Very small top_k may reduce vocabulary diversity; moderate values often fine.\n",
    "- Max output length(num_predict)\n",
    "  - Larger num_predict permits longer outputs (until the model naturally stops)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61a0159d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silver light, her heart's delight\n",
      "She watches moonbeams dance through night\n",
      "Her eyes aglow, like stars above\n",
      "A feline dreamer, under lunar love\n",
      "She purrs and sleeps, in gentle moonlight.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "import os\n",
    "\n",
    "# Tune parameters of LLM in Ollama\n",
    "llm_poem = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    ")\n",
    " \n",
    "PROMPT = \"Write a short (3–5 lines) poem about a cat that loves the moon.\"\n",
    "poem_demo = llm_poem.invoke(PROMPT).content\n",
    "print(poem_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4d5ba3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready: llama3.2 @ http://localhost:11434\n"
     ]
    }
   ],
   "source": [
    "import os, pandas as pd\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Config\n",
    "OLLAMA_BASE = os.getenv(\"OLLAMA_BASE\", \"http://localhost:11434\")\n",
    "MODEL = \"llama3.2\"\n",
    "PROMPT = \"Write a short (3–5 lines) poem about a cat that loves the moon.\"\n",
    "\n",
    "def run(prompt: str, **opts):\n",
    "    \"\"\"Invoke once with given options; return text + a few metrics for comparison.\"\"\"\n",
    "    llm = ChatOllama(model=MODEL, base_url=OLLAMA_BASE, **opts)\n",
    "    msg = llm.invoke(prompt)\n",
    "    meta = getattr(msg, \"response_metadata\", {}) or {}\n",
    "    text = (msg.content or \"\").strip()\n",
    "    # tokens/sec based on generation time\n",
    "    eval_ns = meta.get(\"eval_duration\", 0) or 0\n",
    "    tps = (meta.get(\"eval_count\", 0) / (eval_ns / 1e9)) if eval_ns else None\n",
    "    return text, {\n",
    "        \"prompt_tokens\": meta.get(\"prompt_eval_count\", 0),\n",
    "        \"out_tokens\": meta.get(\"eval_count\", 0),\n",
    "        \"tps_gen\": None if tps is None else round(tps, 2),\n",
    "    }\n",
    "\n",
    "def preview(text: str, n: int = 140) -> str:\n",
    "    s = (text or \"\").replace(\"\\n\", \" ⏎ \")\n",
    "    return s[:n] + (\"…\" if len(s) > n else \"\")\n",
    "\n",
    "print(\"Ready:\", MODEL, \"@\", OLLAMA_BASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3718a619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_512ac th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_512ac td {\n",
       "  vertical-align: top;\n",
       "}\n",
       "#T_512ac_row0_col8, #T_512ac_row1_col8, #T_512ac_row2_col8, #T_512ac_row3_col8, #T_512ac_row4_col8, #T_512ac_row5_col8, #T_512ac_row6_col8, #T_512ac_row7_col8 {\n",
       "  white-space: pre-wrap;\n",
       "  font-family: monospace;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_512ac\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_512ac_level0_col0\" class=\"col_heading level0 col0\" >temperature</th>\n",
       "      <th id=\"T_512ac_level0_col1\" class=\"col_heading level0 col1\" >top_p</th>\n",
       "      <th id=\"T_512ac_level0_col2\" class=\"col_heading level0 col2\" >top_k</th>\n",
       "      <th id=\"T_512ac_level0_col3\" class=\"col_heading level0 col3\" >repeat_penalty</th>\n",
       "      <th id=\"T_512ac_level0_col4\" class=\"col_heading level0 col4\" >num_predict</th>\n",
       "      <th id=\"T_512ac_level0_col5\" class=\"col_heading level0 col5\" >seed</th>\n",
       "      <th id=\"T_512ac_level0_col6\" class=\"col_heading level0 col6\" >out_tokens</th>\n",
       "      <th id=\"T_512ac_level0_col7\" class=\"col_heading level0 col7\" >tps_gen</th>\n",
       "      <th id=\"T_512ac_level0_col8\" class=\"col_heading level0 col8\" >Poem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >label</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_512ac_level0_row0\" class=\"row_heading level0 row0\" >baseline</th>\n",
       "      <td id=\"T_512ac_row0_col0\" class=\"data row0 col0\" >0.700000</td>\n",
       "      <td id=\"T_512ac_row0_col1\" class=\"data row0 col1\" >0.900000</td>\n",
       "      <td id=\"T_512ac_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "      <td id=\"T_512ac_row0_col3\" class=\"data row0 col3\" >None</td>\n",
       "      <td id=\"T_512ac_row0_col4\" class=\"data row0 col4\" >256</td>\n",
       "      <td id=\"T_512ac_row0_col5\" class=\"data row0 col5\" >42</td>\n",
       "      <td id=\"T_512ac_row0_col6\" class=\"data row0 col6\" >46</td>\n",
       "      <td id=\"T_512ac_row0_col7\" class=\"data row0 col7\" >57.560000</td>\n",
       "      <td id=\"T_512ac_row0_col8\" class=\"data row0 col8\" >Silver light upon her back,\n",
       "The moon's soft glow, her favorite fact.\n",
       "She purrs with joy, and eyes aglow,\n",
       "Her love for night, forever to show.\n",
       "In lunar beams, she finds her place.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_512ac_level0_row1\" class=\"row_heading level0 row1\" >temp=0.0</th>\n",
       "      <td id=\"T_512ac_row1_col0\" class=\"data row1 col0\" >0.200000</td>\n",
       "      <td id=\"T_512ac_row1_col1\" class=\"data row1 col1\" >0.900000</td>\n",
       "      <td id=\"T_512ac_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_512ac_row1_col3\" class=\"data row1 col3\" >None</td>\n",
       "      <td id=\"T_512ac_row1_col4\" class=\"data row1 col4\" >256</td>\n",
       "      <td id=\"T_512ac_row1_col5\" class=\"data row1 col5\" >42</td>\n",
       "      <td id=\"T_512ac_row1_col6\" class=\"data row1 col6\" >49</td>\n",
       "      <td id=\"T_512ac_row1_col7\" class=\"data row1 col7\" >84.730000</td>\n",
       "      <td id=\"T_512ac_row1_col8\" class=\"data row1 col8\" >Under lunar light, she purrs with glee,\n",
       "A midnight stalker, wild and free.\n",
       "Her eyes shine bright like stars above,\n",
       "As she dances to the moon's soft love.\n",
       "In its gentle beams, her heart finds home.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_512ac_level0_row2\" class=\"row_heading level0 row2\" >temp=1.2</th>\n",
       "      <td id=\"T_512ac_row2_col0\" class=\"data row2 col0\" >1.200000</td>\n",
       "      <td id=\"T_512ac_row2_col1\" class=\"data row2 col1\" >0.900000</td>\n",
       "      <td id=\"T_512ac_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "      <td id=\"T_512ac_row2_col3\" class=\"data row2 col3\" >None</td>\n",
       "      <td id=\"T_512ac_row2_col4\" class=\"data row2 col4\" >256</td>\n",
       "      <td id=\"T_512ac_row2_col5\" class=\"data row2 col5\" >42</td>\n",
       "      <td id=\"T_512ac_row2_col6\" class=\"data row2 col6\" >47</td>\n",
       "      <td id=\"T_512ac_row2_col7\" class=\"data row2 col7\" >81.970000</td>\n",
       "      <td id=\"T_512ac_row2_col8\" class=\"data row2 col8\" >Softly creeps the feline form,\n",
       "Drawn to moonbeams on the storm,\n",
       "Her eyes aglow with lunar light,\n",
       "A midnight dancer, lost in sight.\n",
       "In moonlit nights, she's free to roam.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_512ac_level0_row3\" class=\"row_heading level0 row3\" >seed=80</th>\n",
       "      <td id=\"T_512ac_row3_col0\" class=\"data row3 col0\" >0.700000</td>\n",
       "      <td id=\"T_512ac_row3_col1\" class=\"data row3 col1\" >0.900000</td>\n",
       "      <td id=\"T_512ac_row3_col2\" class=\"data row3 col2\" >nan</td>\n",
       "      <td id=\"T_512ac_row3_col3\" class=\"data row3 col3\" >None</td>\n",
       "      <td id=\"T_512ac_row3_col4\" class=\"data row3 col4\" >256</td>\n",
       "      <td id=\"T_512ac_row3_col5\" class=\"data row3 col5\" >80</td>\n",
       "      <td id=\"T_512ac_row3_col6\" class=\"data row3 col6\" >47</td>\n",
       "      <td id=\"T_512ac_row3_col7\" class=\"data row3 col7\" >83.830000</td>\n",
       "      <td id=\"T_512ac_row3_col8\" class=\"data row3 col8\" >Silver light, you beckon me,\n",
       "A midnight feline, wild and free.\n",
       "I prowl beneath your gentle glow,\n",
       "My whiskers twitching, my heart aglow.\n",
       "In lunar dreams, I am meant to be.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_512ac_level0_row4\" class=\"row_heading level0 row4\" >top_p=0.6</th>\n",
       "      <td id=\"T_512ac_row4_col0\" class=\"data row4 col0\" >0.700000</td>\n",
       "      <td id=\"T_512ac_row4_col1\" class=\"data row4 col1\" >0.600000</td>\n",
       "      <td id=\"T_512ac_row4_col2\" class=\"data row4 col2\" >nan</td>\n",
       "      <td id=\"T_512ac_row4_col3\" class=\"data row4 col3\" >None</td>\n",
       "      <td id=\"T_512ac_row4_col4\" class=\"data row4 col4\" >256</td>\n",
       "      <td id=\"T_512ac_row4_col5\" class=\"data row4 col5\" >42</td>\n",
       "      <td id=\"T_512ac_row4_col6\" class=\"data row4 col6\" >44</td>\n",
       "      <td id=\"T_512ac_row4_col7\" class=\"data row4 col7\" >83.780000</td>\n",
       "      <td id=\"T_512ac_row4_col8\" class=\"data row4 col8\" >Silver light upon her back,\n",
       "The moon's soft glow, she loves to track.\n",
       "In midnight skies, she dances free,\n",
       "A feline queen, beneath the sea.\n",
       "Her heart beats bright, with lunar pace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_512ac_level0_row5\" class=\"row_heading level0 row5\" >top_p=0.98</th>\n",
       "      <td id=\"T_512ac_row5_col0\" class=\"data row5 col0\" >0.700000</td>\n",
       "      <td id=\"T_512ac_row5_col1\" class=\"data row5 col1\" >0.980000</td>\n",
       "      <td id=\"T_512ac_row5_col2\" class=\"data row5 col2\" >nan</td>\n",
       "      <td id=\"T_512ac_row5_col3\" class=\"data row5 col3\" >None</td>\n",
       "      <td id=\"T_512ac_row5_col4\" class=\"data row5 col4\" >256</td>\n",
       "      <td id=\"T_512ac_row5_col5\" class=\"data row5 col5\" >42</td>\n",
       "      <td id=\"T_512ac_row5_col6\" class=\"data row5 col6\" >45</td>\n",
       "      <td id=\"T_512ac_row5_col7\" class=\"data row5 col7\" >82.150000</td>\n",
       "      <td id=\"T_512ac_row5_col8\" class=\"data row5 col8\" >Silver light upon her back,\n",
       "The moon's gentle beams, she'll gladly track.\n",
       "With eyes aglow like shining stone,\n",
       "She purrs and prowls beneath its throne.\n",
       "In lunar love, she finds her home.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_512ac_level0_row6\" class=\"row_heading level0 row6\" >top_k=20</th>\n",
       "      <td id=\"T_512ac_row6_col0\" class=\"data row6 col0\" >0.700000</td>\n",
       "      <td id=\"T_512ac_row6_col1\" class=\"data row6 col1\" >0.900000</td>\n",
       "      <td id=\"T_512ac_row6_col2\" class=\"data row6 col2\" >20.000000</td>\n",
       "      <td id=\"T_512ac_row6_col3\" class=\"data row6 col3\" >None</td>\n",
       "      <td id=\"T_512ac_row6_col4\" class=\"data row6 col4\" >256</td>\n",
       "      <td id=\"T_512ac_row6_col5\" class=\"data row6 col5\" >42</td>\n",
       "      <td id=\"T_512ac_row6_col6\" class=\"data row6 col6\" >46</td>\n",
       "      <td id=\"T_512ac_row6_col7\" class=\"data row6 col7\" >80.530000</td>\n",
       "      <td id=\"T_512ac_row6_col8\" class=\"data row6 col8\" >Silver light upon her back,\n",
       "The moon's soft glow, her favorite fact.\n",
       "She purrs with joy, and eyes aglow,\n",
       "Her love for night, forever to show.\n",
       "In lunar beams, she finds her place.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_512ac_level0_row7\" class=\"row_heading level0 row7\" >num_predict=47</th>\n",
       "      <td id=\"T_512ac_row7_col0\" class=\"data row7 col0\" >0.700000</td>\n",
       "      <td id=\"T_512ac_row7_col1\" class=\"data row7 col1\" >0.900000</td>\n",
       "      <td id=\"T_512ac_row7_col2\" class=\"data row7 col2\" >nan</td>\n",
       "      <td id=\"T_512ac_row7_col3\" class=\"data row7 col3\" >None</td>\n",
       "      <td id=\"T_512ac_row7_col4\" class=\"data row7 col4\" >47</td>\n",
       "      <td id=\"T_512ac_row7_col5\" class=\"data row7 col5\" >42</td>\n",
       "      <td id=\"T_512ac_row7_col6\" class=\"data row7 col6\" >46</td>\n",
       "      <td id=\"T_512ac_row7_col7\" class=\"data row7 col7\" >82.070000</td>\n",
       "      <td id=\"T_512ac_row7_col8\" class=\"data row7 col8\" >Silver light upon her back,\n",
       "The moon's soft glow, her favorite fact.\n",
       "She purrs with joy, and eyes aglow,\n",
       "Her love for night, forever to show.\n",
       "In lunar beams, she finds her place.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a189d151f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Different experiments\n",
    "EXPS = [\n",
    "    {\"label\": \"baseline\",              \"temperature\": 0.7, \"top_p\": 0.9,  \"num_predict\": 256,  \"seed\": 42},\n",
    "    {\"label\": \"temp=0.0\",              \"temperature\": 0.2, \"top_p\": 0.9,  \"num_predict\": 256, \"seed\": 42},\n",
    "    {\"label\": \"temp=1.2\",              \"temperature\": 1.2, \"top_p\": 0.9,  \"num_predict\": 256, \"seed\": 42},\n",
    "    {\"label\": \"seed=80\",              \"temperature\": 0.7, \"top_p\": 0.9,  \"num_predict\": 256, \"seed\": 80},\n",
    "    {\"label\": \"top_p=0.6\",             \"temperature\": 0.7, \"top_p\": 0.6,  \"num_predict\": 256, \"seed\": 42},\n",
    "    {\"label\": \"top_p=0.98\",            \"temperature\": 0.7, \"top_p\": 0.98, \"num_predict\": 256, \"seed\": 42},\n",
    "    {\"label\": \"top_k=20\",              \"temperature\": 0.7, \"top_p\": 0.9,  \"top_k\": 20,        \"num_predict\": 256, \"seed\": 42},\n",
    "    {\"label\": \"num_predict=47\",        \"temperature\": 0.7, \"top_p\": 0.9,  \"num_predict\": 47,  \"seed\": 42},\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for exp in EXPS:\n",
    "    opts = {k: v for k, v in exp.items() if k != \"label\"}\n",
    "    text, m = run(PROMPT, **opts)\n",
    "    rows.append({\n",
    "        \"label\": exp[\"label\"],\n",
    "        \"temperature\": opts.get(\"temperature\"),\n",
    "        \"top_p\": opts.get(\"top_p\"),\n",
    "        \"top_k\": opts.get(\"top_k\"),\n",
    "        \"repeat_penalty\": opts.get(\"repeat_penalty\"),\n",
    "        \"num_predict\": opts.get(\"num_predict\"),\n",
    "        \"seed\": opts.get(\"seed\"),\n",
    "        \"out_tokens\": m[\"out_tokens\"],\n",
    "        \"tps_gen\": m[\"tps_gen\"],\n",
    "        \"Poem\": text,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).set_index(\"label\")\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "styled = (\n",
    "    df.style\n",
    "      .set_properties(subset=['Poem'], **{\n",
    "          'white-space': 'pre-wrap',   \n",
    "          'font-family': 'monospace',  \n",
    "      })\n",
    "      .set_table_styles([\n",
    "          {'selector': 'th', 'props': [('text-align', 'left')]},\n",
    "          {'selector': 'td', 'props': [('vertical-align', 'top')]}\n",
    "      ])\n",
    ")\n",
    "\n",
    "display(styled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c7807",
   "metadata": {},
   "source": [
    "### Prompting \n",
    "\n",
    "There're a few prompt styles: zero-shot, few-shot, role + constraints, and structured JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd8f69fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three simple explanations of Artificial Intelligence (AI) in plain language:\n",
      "\n",
      "• **AI is like a super-smart computer**: AI uses special algorithms and data to learn from information, make decisions, and solve problems on its own. It's designed to perform tasks that would be difficult or time-consuming for humans.\n",
      "\n",
      "• **AI can learn and improve over time**: Unlike traditional computers, which follow pre-programmed instructions, AI systems can adjust their behavior based on new information and experiences. This means they can get better at what they do with each use, kind of like how we learn from our mistakes!\n",
      "\n",
      "• **AI is used in many areas, not just tech**: While AI is often associated with technology, it's actually being applied to all sorts of fields, such as healthcare, finance, transportation, and even education. It can help analyze data, recognize patterns, and make predictions – making life easier and more efficient for people!\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\", base_url=OLLAMA_BASE, temperature=0.3)\n",
    "\n",
    "prompt = \"\"\"You are a helpful assistant.\n",
    "Explain the concept of Artificial Intelligence in 3 bullet points, plain language.\"\"\"\n",
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b969cda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you have a super smart robot friend! \n",
      "\n",
      "This robot is called Artificial Intelligence, or AI for short.\n",
      "\n",
      "It's like a computer that can think and learn, just like YOU!\n",
      "\n",
      "But instead of using toys and blocks, it uses special math and codes to understand the world.\n",
      "\n",
      "AI can help us with lots of things, like:\n",
      "\n",
      "* Playing games with us\n",
      "* Recognizing pictures and faces\n",
      "* Even helping doctors make people feel better\n",
      "\n",
      "It's like having a magic helper that makes our lives easier!\n",
      "\n",
      "But remember, AI is still just a machine, so we need to be kind and teach it nice things too!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "msgs = [\n",
    "    SystemMessage(content=\"You are a precise technical writer. Use short, formal sentences.\"),\n",
    "    HumanMessage(content=\"Explain AI to a 5-year-old in a playful tone.\"),\n",
    "]\n",
    "print(llm.invoke(msgs).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c9b693f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence refers to the development of computer systems that can perform tasks that typically require human intelligence, such as learning, problem-solving, and decision-making.\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = \"\"\"\n",
    "You are a concise assistant. Answer with one sentence.\n",
    "\n",
    "Q: What is tokenization in NLP?\n",
    "A: Converting text into smaller units (tokens) for processing.\n",
    "\n",
    "Q: What is a vector embedding?\n",
    "A: A numeric representation of text that captures semantic meaning.\n",
    "\n",
    "Q: What is Artificial Intelligence?\n",
    "A:\n",
    "\"\"\".strip()\n",
    "\n",
    "print(llm.invoke(few_shot_prompt).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e02f69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Artificial Intelligence (AI) refers to the simulation of human intelligence in machines.\n",
      "* AI systems use algorithms and data to perform tasks that typically require human intelligence.\n",
      "* The goal of AI is to create machines that can think and learn like humans.\n"
     ]
    }
   ],
   "source": [
    "role_prompt = \"\"\"\n",
    "## SYSTEM\n",
    "You are a technical writing assistant. Be precise and avoid fluff.\n",
    "\n",
    "## TASK\n",
    "Summarize the definition of Artificial Intelligence.\n",
    "\n",
    "## REQUIREMENTS\n",
    "- 3 bullet points\n",
    "- Each bullet ≤ 15 words\n",
    "- No marketing language\n",
    "\"\"\".strip()\n",
    "\n",
    "print(llm.invoke(role_prompt).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f930f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output:\n",
      " Here is the JSON object:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"title\": \"Definition of Artificial Intelligence\",\n",
      "    \"summary\": \"Artificial intelligence (AI) refers to the simulation of human intelligence in machines, enabling them to perform tasks that typically require human intelligence.\",\n",
      "    \"keywords\": [\"Machine Learning\", \"Deep Learning\", \"Natural Language Processing\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Structured JSON output\n",
    "\n",
    "import json, re\n",
    "\n",
    "json_prompt = \"\"\"\n",
    "Return a JSON object with keys: \"title\", \"summary\", and \"keywords\".\n",
    "Topic: \"Definition of Artificial Intelligence\"\n",
    "Keep summary < 40 words. keywords = array of 3–5 short items.\n",
    "\"\"\".strip()\n",
    "\n",
    "raw = llm.invoke(json_prompt).content\n",
    "print(\"Raw output:\\n\", raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7203d587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRAFT:\n",
      " Artificial Intelligence (AI) refers to computer systems that can think and learn like humans, using algorithms and data to make decisions and perform tasks on their own. These systems can be used for a wide range of applications, from simple automation to complex problem-solving, and are becoming increasingly integrated into many aspects of modern life. \n",
      "\n",
      "FINAL:\n",
      " Computer systems that think and learn like humans use algorithms and data to make decisions and perform tasks on their own. They're used in various applications, including automation and problem-solving.\n"
     ]
    }
   ],
   "source": [
    "draft = llm.invoke(\"Define AI in 2 sentences, plain language.\").content\n",
    "\n",
    "critique_prompt = f\"\"\"\n",
    "You will refine the draft to meet ALL constraints:\n",
    "- ≤ 35 words total\n",
    "- No marketing language\n",
    "- Avoid buzzwords\n",
    "\n",
    "DRAFT:\n",
    "{draft}\n",
    "\n",
    "Return the FINAL version only.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"DRAFT:\\n\", draft, \"\\n\")\n",
    "print(\"FINAL:\\n\", llm.invoke(critique_prompt).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36256e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_70f2b th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_70f2b td {\n",
       "  vertical-align: top;\n",
       "}\n",
       "#T_70f2b_row0_col2, #T_70f2b_row1_col2, #T_70f2b_row2_col2, #T_70f2b_row3_col2 {\n",
       "  white-space: pre-wrap;\n",
       "  font-family: monospace;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_70f2b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_70f2b_level0_col0\" class=\"col_heading level0 col0\" >method</th>\n",
       "      <th id=\"T_70f2b_level0_col1\" class=\"col_heading level0 col1\" >prompt</th>\n",
       "      <th id=\"T_70f2b_level0_col2\" class=\"col_heading level0 col2\" >output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_70f2b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_70f2b_row0_col0\" class=\"data row0 col0\" >Answer-only</td>\n",
       "      <td id=\"T_70f2b_row0_col1\" class=\"data row0 col1\" >Solve the problem and output ONLY the final integer answer.\n",
       "No units. No steps. No explanation.\n",
       "\n",
       "Problem: What is the sum of the first 10 positive integers?</td>\n",
       "      <td id=\"T_70f2b_row0_col2\" class=\"data row0 col2\" >55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70f2b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_70f2b_row1_col0\" class=\"data row1 col0\" >Brief rationale</td>\n",
       "      <td id=\"T_70f2b_row1_col1\" class=\"data row1 col1\" >Solve the problem. Provide:\n",
       "1) Brief rationale in ≤ 15 words\n",
       "2) Final answer on a new line as: ANSWER: <number>\n",
       "\n",
       "Problem: What is the sum of the first 10 positive integers?</td>\n",
       "      <td id=\"T_70f2b_row1_col2\" class=\"data row1 col2\" >Rationale: Using the formula for the sum of an arithmetic series, S = n(n+1)/2.\n",
       "\n",
       "ANSWER: 55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70f2b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_70f2b_row2_col0\" class=\"data row2 col0\" >Plan → Answer</td>\n",
       "      <td id=\"T_70f2b_row2_col1\" class=\"data row2 col1\" >Create a very short 3-step plan (each ≤ 5 words) to solve:\n",
       "\n",
       "What is the sum of the first 10 positive integers?\n",
       "\n",
       "Then on a new line, output final answer as:\n",
       "ANSWER: <number>\n",
       "\n",
       "Do not show intermediate calculations.</td>\n",
       "      <td id=\"T_70f2b_row2_col2\" class=\"data row2 col2\" >Step 1: List first 10 numbers.\n",
       "Step 2: Add them together quickly.\n",
       "Step 3: Get total sum result.\n",
       "\n",
       "ANSWER: 55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70f2b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_70f2b_row3_col0\" class=\"data row3 col0\" >Self-Consistency (majority)</td>\n",
       "      <td id=\"T_70f2b_row3_col1\" class=\"data row3 col1\" >Solve the problem and output ONLY the final integer answer.\n",
       "No units. No steps. No explanation.\n",
       "\n",
       "Problem: What is the sum of the first 10 positive integers?\n",
       "\n",
       "(Self-consistency: 7 samples, temp=0.8, seeds=1..7)</td>\n",
       "      <td id=\"T_70f2b_row3_col2\" class=\"data row3 col2\" >55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a18c0751f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-Consistency vote distribution: 55×4, 10×2, 1×1\n"
     ]
    }
   ],
   "source": [
    "# Example: Math problem solving with different prompt styles + self-consistency\n",
    "\n",
    "import os, re, collections, pandas as pd\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Config\n",
    "OLLAMA_BASE = os.getenv(\"OLLAMA_BASE\", \"http://localhost:11434\")\n",
    "MODEL = \"llama3.2\"\n",
    "QUESTION = \"What is the sum of the first 10 positive integers?\"\n",
    "\n",
    "# LLMs (tweak temps if you like)\n",
    "llm        = ChatOllama(model=MODEL, base_url=OLLAMA_BASE, temperature=0.2)\n",
    "llm_brief  = ChatOllama(model=MODEL, base_url=OLLAMA_BASE, temperature=0.3)\n",
    "llm_plan   = ChatOllama(model=MODEL, base_url=OLLAMA_BASE, temperature=0.4)\n",
    "\n",
    "# Prompts\n",
    "prompt_answer_only = f\"\"\"\n",
    "Solve the problem and output ONLY the final integer answer.\n",
    "No units. No steps. No explanation.\n",
    "\n",
    "Problem: {QUESTION}\n",
    "\"\"\".strip()\n",
    "\n",
    "# Brief rationale\n",
    "prompt_brief = f\"\"\"\n",
    "Solve the problem. Provide:\n",
    "1) Brief rationale in ≤ 15 words\n",
    "2) Final answer on a new line as: ANSWER: <number>\n",
    "\n",
    "Problem: {QUESTION}\n",
    "\"\"\".strip()\n",
    "\n",
    "# Plan\n",
    "prompt_plan = f\"\"\"\n",
    "Create a very short 3-step plan (each ≤ 5 words) to solve:\n",
    "\n",
    "{QUESTION}\n",
    "\n",
    "Then on a new line, output final answer as:\n",
    "ANSWER: <number>\n",
    "\n",
    "Do not show intermediate calculations.\n",
    "\"\"\".strip()\n",
    "\n",
    "# Self-consistency helper\n",
    "def answer_only_sample(q, seed=None, temp=0.8):\n",
    "    llm_sc = ChatOllama(model=MODEL, base_url=OLLAMA_BASE, temperature=temp, seed=seed)\n",
    "    m = llm_sc.invoke(f\"Solve and output ONLY the final integer answer.\\n\\nProblem: {q}\")\n",
    "    txt = (m.content or \"\").strip()\n",
    "    nums = re.findall(r\"-?\\d+\", txt)\n",
    "    return nums[0] if nums else txt\n",
    "\n",
    "# Gather outputs\n",
    "ans_only = llm.invoke(prompt_answer_only).content.strip()\n",
    "brief    = llm_brief.invoke(prompt_brief).content.strip()\n",
    "plan     = llm_plan.invoke(prompt_plan).content.strip()\n",
    "\n",
    "top_counts = counter.most_common()\n",
    "top_counts_str = \", \".join(f\"{ans}×{cnt}\" for ans, cnt in top_counts)\n",
    "sc_note = \"(Self-consistency: 7 samples, temp=0.8, seeds=1..7)\"\n",
    "sc_prompt_text = prompt_answer_only + \"\\n\\n\" + sc_note\n",
    "\n",
    "\n",
    "# Self-consistency majority vote\n",
    "answers  = [answer_only_sample(QUESTION, seed=s) for s in [1,2,3,4,5,6,7]]\n",
    "counter  = collections.Counter(answers)\n",
    "majority = counter.most_common(1)[0][0]\n",
    "\n",
    "# Build table\n",
    "rows = [\n",
    "    {\"method\": \"Answer-only\", \"prompt\": prompt_answer_only, \"output\": ans_only},\n",
    "    {\"method\": \"Brief rationale\", \"prompt\": prompt_brief, \"output\": brief},\n",
    "    {\"method\": \"Plan → Answer\", \"prompt\": prompt_plan, \"output\": plan},\n",
    "    {\"method\": \"Self-Consistency (majority)\", \"prompt\": sc_prompt_text, \"output\": majority},\n",
    "]\n",
    "\n",
    "df_prompt = pd.DataFrame(rows)\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "styled_prompt_table = (\n",
    "    df_prompt.style\n",
    "      .set_properties(subset=['output'], **{\n",
    "          'white-space': 'pre-wrap', \n",
    "          'font-family': 'monospace', \n",
    "      })\n",
    "      .set_table_styles([\n",
    "          {'selector': 'th', 'props': [('text-align', 'left')]},\n",
    "          {'selector': 'td', 'props': [('vertical-align', 'top')]},\n",
    "      ])\n",
    ")\n",
    "display(styled_prompt_table)\n",
    "\n",
    "print(\"Self-Consistency vote distribution:\", top_counts_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217339be",
   "metadata": {},
   "source": [
    "---\n",
    "### Build Simple Chatbot Interface:\n",
    "\n",
    "- Streamlit\n",
    "- Gradio\n",
    "- Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "afcdfa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\60175\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\60175\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\60175\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chainlit 1.3.2 requires packaging<24.0,>=23.1, but you have packaging 24.2 which is incompatible.\n",
      "chainlit 1.3.2 requires python-multipart<0.0.10,>=0.0.9, but you have python-multipart 0.0.20 which is incompatible.\n",
      "crawl4ai 0.5.0.post6 requires aiofiles>=24.1.0, but you have aiofiles 23.2.1 which is incompatible.\n",
      "graphrag 0.0.1.dev49 requires aiofiles<25.0.0,>=24.1.0, but you have aiofiles 23.2.1 which is incompatible.\n",
      "graphrag 0.0.1.dev49 requires nltk==3.8.1, but you have nltk 3.9.1 which is incompatible.\n",
      "graphrag 0.0.1.dev49 requires tenacity<9.0.0,>=8.5.0, but you have tenacity 9.0.0 which is incompatible.\n",
      "graphrag 0.0.1.dev49 requires tiktoken<0.8.0,>=0.7.0, but you have tiktoken 0.11.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.44.0)\n",
      "Requirement already satisfied: gradio in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (5.9.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.2.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.3.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.28.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (21.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.32.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (4.15.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (4.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (3.1.41)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (6.4)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (4.7.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.115.4)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.5.2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (1.5.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.27.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.35.1)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (3.10.11)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.10.4)\n",
      "Requirement already satisfied: pydub in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.8.4)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.41.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.12.5)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.25.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio-client==1.5.2->gradio) (2024.9.0)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio-client==1.5.2->gradio) (13.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2023.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (1.26.18)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.17.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\60175\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: aiofiles\n",
      "  Attempting uninstall: aiofiles\n",
      "    Found existing installation: aiofiles 24.1.0\n",
      "    Uninstalling aiofiles-24.1.0:\n",
      "      Successfully uninstalled aiofiles-24.1.0\n",
      "Successfully installed aiofiles-23.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fc5f3df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, gradio as gr\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "OLLAMA_BASE = os.getenv(\"OLLAMA_BASE\", \"http://localhost:11434\")\n",
    "llm = ChatOllama(model=\"llama3.2\", base_url=OLLAMA_BASE, temperature=0.2)\n",
    "\n",
    "def reply(message, history): \n",
    "    out = llm.invoke(message).content\n",
    "    return out\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=reply,\n",
    "    title=\"Simple Chatbot (Gradio + Ollama)\",\n",
    "    description=\"Type a message and get a response from a local model.\",\n",
    ")\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
